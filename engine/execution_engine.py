# engine/execution_engine.py
from typing import List, Dict, Any, Optional, Tuple
from engine.storage_engine import StorageEngine
from catalog.catalog_manager import CatalogManager
from sql_compiler.codegen.operators import (Operator, CreateTableOp, InsertOp, SeqScanOp, FilterOp, ProjectOp, UpdateOp, \
    DeleteOp, OptimizedSeqScanOp, GroupByOp, OrderByOp, JoinOp, FilteredSeqScanOp, IndexScanOp, IndexOnlyScanOp, CreateIndexOp,
    DropIndexOp, BeginTransactionOp, CommitTransactionOp, RollbackTransactionOp, CreateViewOp, DropViewOp, ShowViewsOp,
    DescribeViewOp, ViewScanOp, ShowIndexesOp)
from sql_compiler.exceptions.compiler_errors import SemanticError
from sql_compiler.semantic.symbol_table import SymbolTable
from sql_compiler.semantic.type_checker import TypeChecker
from storage.core.transaction_manager import TransactionManager, IsolationLevel  # æ·»åŠ äº‹åŠ¡ç®¡ç†å™¨å¯¼å…¥
from sql_compiler.parser.ast_nodes import TableRef
import logging

# æ·»åŠ æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger("execution_engine")

class ExecutionEngine:
    def __init__(self, storage_engine: StorageEngine, catalog_manager: CatalogManager):
        self.storage_engine = storage_engine
        self.catalog = catalog_manager
        self.symbol_table = SymbolTable()
        self.type_checker = TypeChecker(self.symbol_table)

        # æ·»åŠ äº‹åŠ¡ç›¸å…³å±æ€§
        self.transaction_manager = None
        self.current_transaction_id = None
        self.transaction_mode = None
        self.isolation_level = IsolationLevel.READ_COMMITTED

        # æ·»åŠ è§†å›¾ç›¸å…³å±æ€§
        self.views = {}  # å­˜å‚¨è§†å›¾å®šä¹‰

        # æ·»åŠ æ—¥å¿—è®°å½•å™¨å®ä¾‹
        self.logger = logging.getLogger("execution_engine")

    def set_transaction_manager(self, transaction_manager: TransactionManager):
        """è®¾ç½®äº‹åŠ¡ç®¡ç†å™¨"""
        self.transaction_manager = transaction_manager

    def begin_transaction(self, isolation_level: IsolationLevel = IsolationLevel.READ_COMMITTED) -> int:
        """å¼€å§‹ä¸€ä¸ªæ–°äº‹åŠ¡"""
        if self.transaction_manager is None:
            raise SemanticError("Transaction manager not initialized")

        self.current_transaction_id = self.transaction_manager.begin_transaction(isolation_level)
        self.isolation_level = isolation_level
        return self.current_transaction_id

    def commit_transaction(self) -> bool:
        """æäº¤å½“å‰äº‹åŠ¡"""
        if self.current_transaction_id is None:
            raise SemanticError("No active transaction to commit")

        if self.transaction_manager is None:
            raise SemanticError("Transaction manager not initialized")

        try:
            self.transaction_manager.commit(self.current_transaction_id)
            self.current_transaction_id = None
            return True
        except Exception as e:
            raise SemanticError(f"Failed to commit transaction: {str(e)}")

    # execution_engine.py ä¸­çš„ä¿®æ”¹

    def rollback_transaction(self) -> bool:
        """å›æ»šå½“å‰äº‹åŠ¡"""
        if self.current_transaction_id is None:
            # æ”¹ä¸ºè¿”å›æˆåŠŸè€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯ï¼Œå› ä¸ºROLLBACKåœ¨æ²¡æœ‰äº‹åŠ¡æ—¶æ˜¯å…è®¸çš„
            print("WARNING: No active transaction to rollback - this is allowed in SQL")
            return True

        if self.transaction_manager is None:
            raise SemanticError("Transaction manager not initialized")

        try:
            # ç¡®ä¿ä¼ é€’äº‹åŠ¡IDç»™å­˜å‚¨å¼•æ“
            success = self.storage_engine.rollback_transaction(self.current_transaction_id)
            if success:
                self.current_transaction_id = None
            return success
        except Exception as e:
            # æ·»åŠ è¯¦ç»†é”™è¯¯æ—¥å¿—
            print(f"ERROR: Failed to rollback transaction {self.current_transaction_id}: {str(e)}")
            # å°è¯•å¼ºåˆ¶æ¸…ç†äº‹åŠ¡
            try:
                if self.transaction_manager:
                    self.transaction_manager.force_cleanup_transaction(self.current_transaction_id)
            except Exception as cleanup_error:
                print(f"ERROR: Failed to cleanup transaction during rollback: {cleanup_error}")
            self.current_transaction_id = None
            raise SemanticError(f"Failed to rollback transaction: {str(e)}")

    def get_transaction_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰äº‹åŠ¡çŠ¶æ€"""
        if self.current_transaction_id is None:
            return {"status": "NO_ACTIVE_TRANSACTION"}

        if self.transaction_manager is None:
            return {"status": "TRANSACTION_MANAGER_NOT_INITIALIZED"}

        txn = self.transaction_manager.get_transaction(self.current_transaction_id)
        if txn:
            return {
                "status": "ACTIVE",
                "transaction_id": self.current_transaction_id,
                "isolation_level": txn.isolation_level.name,
                "state": txn.state.name
            }
        else:
            return {"status": "TRANSACTION_NOT_FOUND"}

    # åœ¨ execute_plan æ–¹æ³•ä¸­æ·»åŠ è¿™ä¸ªåˆ†æ”¯
    def execute_plan(self, plan: Operator) -> Any:
        """æ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’ - ä¿®å¤GroupByæ‰§è¡Œ"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†å›¾æ‰«æ
            if isinstance(plan, SeqScanOp) and plan.table_name in self.views:
                # è¿™æ˜¯è§†å›¾ï¼Œæ‰§è¡Œè§†å›¾å®šä¹‰
                view_info = self.views[plan.table_name]
                if 'plan' in view_info:
                    # æ‰§è¡Œè§†å›¾çš„SELECTè®¡åˆ’
                    return self.execute_plan(view_info['plan'])
                else:
                    # å›é€€åˆ°ç›´æ¥ä½¿ç”¨è§†å›¾å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
                    return view_info.get('definition', [])

            # æ£€æŸ¥æ˜¯å¦ä¸ºäº‹åŠ¡æ“ä½œ
            if hasattr(plan, 'operation_type'):
                if plan.operation_type == 'BEGIN_TRANSACTION':
                    isolation_level = getattr(plan, 'isolation_level', IsolationLevel.READ_COMMITTED)
                    txn_id = self.begin_transaction(isolation_level)
                    return f"Transaction {txn_id} started with isolation level {isolation_level.name}"

                elif plan.operation_type == 'COMMIT_TRANSACTION':
                    self.commit_transaction()
                    return "Transaction committed successfully"

                elif plan.operation_type == 'ROLLBACK_TRANSACTION':
                    self.rollback_transaction()
                    return "Transaction rolled back successfully"

            # æ£€æŸ¥å½“å‰æ˜¯å¦æœ‰æ´»è·ƒäº‹åŠ¡
            if self.current_transaction_id is None and self._requires_transaction(plan):
                # è‡ªåŠ¨å¼€å§‹ä¸€ä¸ªäº‹åŠ¡
                self.begin_transaction()
                print(f"Auto-started transaction {self.current_transaction_id} for operation")

            # æ·»åŠ å¯¹äº‹åŠ¡æ“ä½œç¬¦çš„ç›´æ¥ç±»å‹æ£€æŸ¥
            if isinstance(plan, BeginTransactionOp):
                isolation_level = getattr(plan, 'isolation_level', None)
                if isolation_level is None:
                    isolation_level = IsolationLevel.READ_COMMITTED
                elif isinstance(isolation_level, str):
                    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º IsolationLevel æšä¸¾
                    try:
                        isolation_level = IsolationLevel[isolation_level.upper().replace(' ', '_')]
                    except KeyError:
                        isolation_level = IsolationLevel.READ_COMMITTED

                txn_id = self.begin_transaction(isolation_level)
                return f"Transaction {txn_id} started with isolation level {isolation_level.name}"

            elif isinstance(plan, CommitTransactionOp):
                self.commit_transaction()
                return "Transaction committed successfully"

            elif isinstance(plan, RollbackTransactionOp):
                self.rollback_transaction()
                return "Transaction rolled back successfully"

            # æ·»åŠ è§†å›¾æ“ä½œç¬¦å¤„ç†
            elif isinstance(plan, CreateViewOp):
                return self.execute_create_view(
                    plan.view_name,
                    plan.select_plan,
                    plan.columns,
                    plan.or_replace,
                    plan.materialized,
                    plan.with_check_option
                )
            elif isinstance(plan, DropViewOp):
                return self.execute_drop_view(
                    plan.view_names,
                    plan.if_exists,
                    plan.cascade,
                    plan.materialized
                )
            elif isinstance(plan, ShowViewsOp):
                return self.execute_show_views(plan.pattern, plan.database)
            elif isinstance(plan, DescribeViewOp):
                return self.execute_describe_view(plan.view_name)
            elif isinstance(plan, ViewScanOp):
                return self.execute_view_scan(plan.underlying_plan)

            if isinstance(plan, CreateTableOp):
                return self.execute_create_table(plan.table_name, plan.columns)
            elif isinstance(plan, InsertOp):
                return self.execute_insert(plan.table_name, plan.columns, plan.values)
            # åœ¨ execute_plan æ–¹æ³•ä¸­æ·»åŠ å¯¹ SeqScanOp çš„ç‰¹æ®Šå¤„ç†
            elif isinstance(plan, SeqScanOp):
                # æ£€æŸ¥æ˜¯å¦æ˜¯è§†å›¾
                if plan.table_name in self.views:
                    view_info = self.views[plan.table_name]
                    if 'plan' in view_info:
                        # æ‰§è¡Œè§†å›¾çš„SELECTè®¡åˆ’
                        return self.execute_plan(view_info['plan'])
                    else:
                        # å›é€€åˆ°ç›´æ¥ä½¿ç”¨è§†å›¾å®šä¹‰
                        return view_info.get('definition', [])
                else:
                    return self.execute_seq_scan(plan.table_name)
            elif isinstance(plan, OptimizedSeqScanOp):
                return self.execute_optimized_seq_scan(plan.table_name, plan.selected_columns)
            elif isinstance(plan, FilterOp):
                # å¤„ç†è¿‡æ»¤æ“ä½œ
                child_results = self.execute_plan(plan.children[0])
                return [row for row in child_results if self.evaluate_condition(row, plan.condition)]
            elif isinstance(plan, GroupByOp):
                # ğŸ”‘ ä½¿ç”¨ç‹¬ç«‹çš„execute_group_byæ–¹æ³•ï¼Œä¼ å…¥æ­£ç¡®çš„å‚æ•°
                return self.execute_group_by(
                    group_columns=plan.group_columns,
                    having_condition=plan.having_condition,
                    child_plan=plan.children[0],  # ä¼ å…¥å­è®¡åˆ’è€Œä¸æ˜¯æ‰§è¡Œç»“æœ
                    aggregate_functions=plan.aggregate_functions
                )
            elif isinstance(plan, ProjectOp):
                return self.execute_project(plan.columns, plan.children[0])
            elif isinstance(plan, UpdateOp):
                return self.execute_update(plan.table_name, plan.assignments, plan.children[0])
            elif isinstance(plan, DeleteOp):
                return self.execute_delete(plan.table_name, plan.children[0])
            elif isinstance(plan, OrderByOp):
                return self.execute_order_by(plan.order_columns, plan.children[0])
            elif isinstance(plan, JoinOp):
                return self.execute_join(plan.join_type, plan.on_condition, plan.children)
            elif isinstance(plan, FilteredSeqScanOp):
                return self.execute_filtered_seq_scan(plan.table_name, plan.condition)
            elif isinstance(plan, IndexScanOp):
                return self.execute_index_scan(plan.table_name, plan.index_name, plan.scan_condition)
            elif isinstance(plan, IndexOnlyScanOp):
                return self.execute_index_only_scan(plan.table_name, plan.index_name, plan.scan_condition)
            elif isinstance(plan, CreateIndexOp):
                return self.execute_create_index(plan.index_name, plan.table_name, plan.columns, plan.unique,
                                                 plan.index_type)
            elif isinstance(plan, DropIndexOp):
                return self.execute_drop_index(plan.index_name)
            elif isinstance(plan, ShowIndexesOp):
                return self.execute_show_indexes(plan.table_name)
            else:
                raise SemanticError(f"ä¸æ”¯æŒçš„æ‰§è¡Œè®¡åˆ’ç±»å‹: {type(plan).__name__}")
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶è‡ªåŠ¨å›æ»šäº‹åŠ¡
            if self.current_transaction_id is not None:
                try:
                    self.rollback_transaction()
                    print(f"Auto-rolled back transaction due to error: {str(e)}")
                except:
                    pass  # å¿½ç•¥å›æ»šè¿‡ç¨‹ä¸­çš„é”™è¯¯
            raise SemanticError(f"æ‰§è¡Œé”™è¯¯: {str(e)}")

    # ä¿®æ”¹execute_drop_viewæ–¹æ³•
    # execution_engine.py ä¿®æ”¹éƒ¨åˆ†

    def execute_create_view(self, view_name: str, select_plan: Operator, columns: Optional[List[str]] = None,
                            or_replace: bool = False, materialized: bool = False,
                            with_check_option: bool = False) -> str:
        """æ‰§è¡ŒCREATE VIEWè¯­å¥ - ä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿æŒä¹…åŒ–åˆ°catalog"""
        try:
            # æ£€æŸ¥è§†å›¾æ˜¯å¦å·²å­˜åœ¨
            if view_name in self.views and not or_replace:
                raise SemanticError(f"View '{view_name}' already exists")

            # ä»SELECTè®¡åˆ’æ„å»ºè§†å›¾å®šä¹‰SQL
            view_definition = self._construct_view_definition(
                select_plan, view_name, columns, or_replace, materialized, with_check_option
            )

            # è°ƒç”¨catalog manageråˆ›å»ºè§†å›¾ï¼ˆè¿™ä¼šæŒä¹…åŒ–åˆ°system_catalog.jsonï¼‰
            success = self.catalog.create_view(
                view_name=view_name,
                definition=view_definition,
                columns=columns,
                is_materialized=materialized,
                or_replace=or_replace,
                with_check_option=with_check_option
            )

            if not success:
                raise SemanticError(f"Failed to create view '{view_name}' in catalog")

            # å­˜å‚¨è§†å›¾å®šä¹‰åˆ°å†…å­˜
            self.views[view_name] = {
                'plan': select_plan,  # ä¿å­˜æ‰§è¡Œè®¡åˆ’
                'columns': columns,  # ä¿å­˜è§†å›¾åˆ—å
                'materialized': materialized,
                'with_check_option': with_check_option,
                'definition': view_definition  # ä¿å­˜SQLå®šä¹‰
            }

            # å°è¯•å­˜å‚¨åˆ°æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
            try:
                self.storage_engine.create_view(
                    view_name,
                    view_definition,  # ä½¿ç”¨SQLå®šä¹‰è€Œä¸æ˜¯æ‰§è¡Œè®¡åˆ’
                    columns,
                    materialized,
                    with_check_option
                )
            except Exception as e:
                self.logger.warning(f"Could not persist view '{view_name}' to storage: {e}")

            return f"View '{view_name}' created successfully"
        except Exception as e:
            # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œç¡®ä¿ä»catalogä¸­åˆ é™¤è§†å›¾ï¼ˆå¦‚æœå·²åˆ›å»ºï¼‰
            if self.catalog.view_exists(view_name):
                self.catalog.drop_view(view_name, if_exists=True)
            raise SemanticError(f"åˆ›å»ºè§†å›¾é”™è¯¯: {str(e)}")

    def execute_drop_view(self, view_names: List[str], if_exists: bool = False,
                          cascade: bool = False, materialized: bool = False) -> str:
        """æ‰§è¡ŒDROP VIEWè¯­å¥ - ç¡®ä¿ä»catalogä¸­åˆ é™¤"""
        try:
            dropped_count = 0
            for view_name in view_names:
                # é¦–å…ˆä»catalogä¸­åˆ é™¤è§†å›¾ï¼ˆè¿™ä¼šæŒä¹…åŒ–åˆ°system_catalog.jsonï¼‰
                catalog_success = self.catalog.drop_view(
                    view_name=view_name,
                    if_exists=if_exists,
                    cascade=cascade
                )

                if not catalog_success and not if_exists:
                    raise SemanticError(f"Failed to drop view '{view_name}' from catalog")

                # ç„¶åä»å†…å­˜ä¸­åˆ é™¤è§†å›¾
                if view_name in self.views:
                    del self.views[view_name]
                    dropped_count += 1

                # ä»å­˜å‚¨å¼•æ“åˆ é™¤è§†å›¾
                try:
                    storage_success = self.storage_engine.drop_view(view_name)
                    if not storage_success and not if_exists:
                        self.logger.warning(f"Failed to drop view '{view_name}' from storage")
                except Exception as e:
                    self.logger.warning(f"Error dropping view '{view_name}' from storage: {e}")

            return f"view '{view_name}' dropped successfully"
        except Exception as e:
            raise SemanticError(f"åˆ é™¤è§†å›¾é”™è¯¯: {str(e)}")

    def _construct_view_definition(self, select_plan: Operator, view_name: str, columns: Optional[List[str]] = None,
                                   or_replace: bool = False, materialized: bool = False,
                                   with_check_option: bool = False) -> str:
        """ä»SELECTè®¡åˆ’æ„å»ºè§†å›¾å®šä¹‰SQL"""

        def reconstruct_sql(operator: Operator) -> str:
            """é€’å½’é‡æ„SQLè¯­å¥"""
            if not operator:
                return ""

            operator_type = operator.__class__.__name__

            # å¤„ç†æŠ•å½±æ“ä½œ (SELECTå­å¥)
            if operator_type == "ProjectOp":
                columns = getattr(operator, 'columns', ['*'])
                columns_str = ', '.join(columns)

                # å¤„ç†FROMå­å¥
                from_clause = ""
                if operator.children:
                    from_clause = reconstruct_sql(operator.children[0])

                return f"SELECT {columns_str} FROM {from_clause}"

            # å¤„ç†è¿‡æ»¤æ“ä½œ (WHEREå­å¥)
            elif operator_type == "FilterOp":
                condition = getattr(operator, 'condition', None)
                condition_str = reconstruct_expression(condition) if condition else "1=1"

                child_sql = reconstruct_sql(operator.children[0]) if operator.children else "SELECT *"

                # æ£€æŸ¥child_sqlæ˜¯å¦å·²ç»æœ‰WHEREå­å¥
                if "WHERE" in child_sql.upper():
                    # å¦‚æœå·²ç»æœ‰WHEREï¼Œä½¿ç”¨ANDè¿æ¥
                    return f"{child_sql} AND {condition_str}"
                else:
                    return f"{child_sql} WHERE {condition_str}"

            # å¤„ç†è¿æ¥æ“ä½œ
            elif operator_type == "JoinOp":
                join_type = getattr(operator, 'join_type', 'INNER').upper()
                on_condition = getattr(operator, 'on_condition', None)

                if len(operator.children) >= 2:
                    left_sql = reconstruct_sql(operator.children[0])
                    right_sql = reconstruct_sql(operator.children[1])

                    join_clause = f"{left_sql} {join_type} JOIN {right_sql}"

                    if on_condition:
                        on_str = reconstruct_expression(on_condition)
                        join_clause += f" ON {on_str}"

                    return join_clause
                return ""

            # å¤„ç†åˆ†ç»„æ“ä½œ (GROUP BYå­å¥)
            elif operator_type == "GroupByOp":
                group_columns = getattr(operator, 'group_columns', [])
                having_condition = getattr(operator, 'having_condition', None)
                aggregate_functions = getattr(operator, 'aggregate_functions', [])

                # æ„å»ºSELECTå­å¥ï¼ˆåŒ…å«èšåˆå‡½æ•°ï¼‰
                select_parts = []

                # æ·»åŠ åˆ†ç»„åˆ—
                select_parts.extend(group_columns)

                # æ·»åŠ èšåˆå‡½æ•°
                for func_name, column_name in aggregate_functions:
                    if column_name == '*':
                        select_parts.append(f"{func_name.upper()}(*)")
                    else:
                        select_parts.append(f"{func_name.upper()}({column_name})")

                select_clause = ', '.join(select_parts) if select_parts else '*'

                # æ„å»ºåŸºç¡€SQL
                base_sql = reconstruct_sql(operator.children[0]) if operator.children else "SELECT *"

                # æ›¿æ¢SELECTå­å¥
                if base_sql.upper().startswith('SELECT'):
                    base_sql = f"SELECT {select_clause}" + base_sql[6:]  # ç§»é™¤åŸæ¥çš„SELECTéƒ¨åˆ†

                # æ·»åŠ GROUP BY
                if group_columns:
                    group_by_str = ', '.join(group_columns)
                    base_sql += f" GROUP BY {group_by_str}"

                # æ·»åŠ HAVING
                if having_condition:
                    having_str = reconstruct_expression(having_condition)
                    base_sql += f" HAVING {having_str}"

                return base_sql

            # å¤„ç†æ’åºæ“ä½œ (ORDER BYå­å¥)
            elif operator_type == "OrderByOp" or operator_type == "SortOp":
                order_columns = getattr(operator, 'order_columns', [])
                order_by_parts = []

                for col_info in order_columns:
                    if isinstance(col_info, tuple):
                        column, direction = col_info
                        order_by_parts.append(f"{column} {direction.upper()}")
                    elif isinstance(col_info, dict):
                        column = col_info.get('column', '')
                        direction = col_info.get('direction', 'ASC')
                        order_by_parts.append(f"{column} {direction.upper()}")

                order_by_str = ', '.join(order_by_parts)

                child_sql = reconstruct_sql(operator.children[0]) if operator.children else "SELECT *"

                return f"{child_sql} ORDER BY {order_by_str}"

            # å¤„ç†è¡¨æ‰«ææ“ä½œ
            elif operator_type == "SeqScanOp" or operator_type == "FilteredSeqScanOp":
                table_name = getattr(operator, 'table_name', 'unknown_table')
                table_alias = getattr(operator, 'table_alias', None)

                if table_alias and table_alias != table_name:
                    return f"{table_name} AS {table_alias}"
                return table_name

            # å¤„ç†å­æŸ¥è¯¢
            elif operator_type == "SubqueryOp":
                subquery_sql = reconstruct_sql(operator.select_plan)
                return f"({subquery_sql})"

            # å¤„ç†è”åˆæ“ä½œ
            elif operator_type == "UnionOp":
                union_type = getattr(operator, 'union_type', 'UNION')
                child_sqls = [reconstruct_sql(child) for child in operator.children]
                return f" {union_type} ".join([f"({sql})" for sql in child_sqls])

            # å¤„ç†å“ˆå¸Œèšåˆ
            elif operator_type == "HashAggregateOp":
                group_columns = getattr(operator, 'group_columns', [])
                agg_functions = getattr(operator, 'agg_functions', [])
                having_condition = getattr(operator, 'having_condition', None)

                # æ„å»ºSELECTå­å¥
                select_parts = []
                select_parts.extend(group_columns)

                for agg_func in agg_functions:
                    func_name = agg_func.get('func', '')
                    column = agg_func.get('column', '')
                    alias = agg_func.get('alias', '')

                    if column == '*':
                        agg_expr = f"{func_name.upper()}(*)"
                    else:
                        agg_expr = f"{func_name.upper()}({column})"

                    if alias:
                        select_parts.append(f"{agg_expr} AS {alias}")
                    else:
                        select_parts.append(agg_expr)

                select_clause = ', '.join(select_parts)

                # æ„å»ºåŸºç¡€SQL
                base_sql = reconstruct_sql(operator.children[0]) if operator.children else "SELECT *"

                # æ›¿æ¢SELECTå­å¥
                if base_sql.upper().startswith('SELECT'):
                    base_sql = f"SELECT {select_clause}" + base_sql[6:]

                # æ·»åŠ GROUP BY
                if group_columns:
                    group_by_str = ', '.join(group_columns)
                    base_sql += f" GROUP BY {group_by_str}"

                # æ·»åŠ HAVING
                if having_condition:
                    having_str = reconstruct_expression(having_condition)
                    base_sql += f" HAVING {having_str}"

                return base_sql

            # é»˜è®¤æƒ…å†µï¼šé€’å½’å¤„ç†å­èŠ‚ç‚¹
            elif operator.children:
                child_sqls = [reconstruct_sql(child) for child in operator.children]
                return ' '.join([sql for sql in child_sqls if sql])

            return "SELECT *"

        def reconstruct_expression(expr) -> str:
            """é‡æ„è¡¨è¾¾å¼"""
            if expr is None:
                return ""

            # å¦‚æœæ˜¯å­—å…¸å½¢å¼çš„è¡¨è¾¾å¼ï¼ˆæ¥è‡ªto_dict()ï¼‰
            if isinstance(expr, dict):
                expr_type = expr.get('type', '')

                if expr_type == "BinaryExpr":
                    left = reconstruct_expression(expr.get('left'))
                    operator = expr.get('operator', '=')
                    right = reconstruct_expression(expr.get('right'))
                    return f"{left} {operator} {right}"

                elif expr_type == "IdentifierExpr":
                    table_name = expr.get('table_name')
                    column_name = expr.get('name', 'unknown')
                    if table_name:
                        return f"{table_name}.{column_name}"
                    return column_name

                elif expr_type == "LiteralExpr":
                    value = expr.get('value')
                    if isinstance(value, str):
                        return f"'{value}'"
                    return str(value)

                elif expr_type == "FunctionExpr":
                    func_name = expr.get('function_name', 'UNKNOWN')
                    args = expr.get('arguments', [])
                    args_str = ', '.join([reconstruct_expression(arg) for arg in args])
                    return f"{func_name}({args_str})"

                elif expr_type == "BetweenExpr":
                    expr_val = reconstruct_expression(expr.get('expr'))
                    lower = reconstruct_expression(expr.get('lower'))
                    upper = reconstruct_expression(expr.get('upper'))
                    return f"{expr_val} BETWEEN {lower} AND {upper}"

            # å¦‚æœæ˜¯ASTèŠ‚ç‚¹å¯¹è±¡
            elif hasattr(expr, 'to_dict'):
                return reconstruct_expression(expr.to_dict())

            # å¦‚æœæ˜¯ç®€å•çš„å€¼
            else:
                return str(expr)

        # æ„å»ºå®Œæ•´çš„CREATE VIEWè¯­å¥
        select_statement = reconstruct_sql(select_plan)

        # æ·»åŠ è§†å›¾é€‰é¡¹
        view_options = []
        if or_replace:
            view_options.append("OR REPLACE")
        if materialized:
            view_options.append("MATERIALIZED")
        if with_check_option:
            view_options.append("WITH CHECK OPTION")

        options_str = ' '.join(view_options)

        # æ·»åŠ åˆ—å®šä¹‰
        columns_str = ""
        if columns:
            columns_str = f" ({', '.join(columns)})"

        return f"CREATE {options_str} VIEW {view_name}{columns_str} AS {select_statement}"

    def execute_describe_view(self, view_name: str) -> Dict[str, Any]:
        """æ‰§è¡ŒDESCRIBE VIEWè¯­å¥"""
        try:
            if view_name not in self.views:
                raise SemanticError(f"View '{view_name}' does not exist")

            view_info = self.views[view_name]
            return {
                'name': view_name,
                'columns': view_info['columns'],
                'materialized': view_info['materialized'],
                'with_check_option': view_info['with_check_option'],
                'definition': view_info['definition']
            }
        except Exception as e:
            raise SemanticError(f"æè¿°è§†å›¾é”™è¯¯: {str(e)}")

    def execute_view_scan(self, underlying_plan: Operator) -> List[Dict]:
        """æ‰§è¡Œè§†å›¾æ‰«ææ“ä½œ"""
        try:
            # æ‰§è¡Œåº•å±‚æŸ¥è¯¢è®¡åˆ’
            return self.execute_plan(underlying_plan)
        except Exception as e:
            raise SemanticError(f"è§†å›¾æ‰«æé”™è¯¯: {str(e)}")

    def _pattern_match(self, name: str, pattern: str) -> bool:
        """ç®€å•çš„æ¨¡å¼åŒ¹é…å‡½æ•°"""
        # å°†SQLæ¨¡å¼è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼
        import re
        regex_pattern = pattern.replace('%', '.*').replace('_', '.')
        return re.match(regex_pattern, name) is not None

    def _requires_transaction(self, plan: Operator) -> bool:
        """æ£€æŸ¥æ‰§è¡Œè®¡åˆ’æ˜¯å¦éœ€è¦äº‹åŠ¡æ”¯æŒ"""
        # DMLæ“ä½œéœ€è¦äº‹åŠ¡æ”¯æŒ
        return isinstance(plan, (InsertOp, UpdateOp, DeleteOp))

    # execution_engine.py ä¸­çš„ execute_create_table æ–¹æ³•
    def execute_create_table(self, table_name: str, columns: List[tuple]) -> str:
        """æ‰§è¡ŒCREATE TABLEè¯­å¥"""
        try:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"DEBUG: Creating table {table_name}")
            print(f"DEBUG: Columns received: {columns}")

            # æ£€æŸ¥columnså‚æ•°çš„ç»“æ„
            for i, col_tuple in enumerate(columns):
                print(f"DEBUG: Column {i}: {col_tuple}, type: {type(col_tuple)}, length: {len(col_tuple)}")

            # æ·»åŠ åˆ°ç¬¦å·è¡¨
            self.symbol_table.add_table(table_name, columns)

            # æ·»åŠ åˆ°catalog - ç¡®ä¿ä¼ é€’æ­£ç¡®çš„å‚æ•°æ ¼å¼ï¼ˆå…ƒç»„åˆ—è¡¨ï¼‰
            success = self.catalog.create_table(table_name, columns)
            print(f"DEBUG: Catalog create_table result: {success}")

            # å°†columnsæ ¼å¼ä»tupleåˆ—è¡¨è½¬æ¢ä¸ºdictåˆ—è¡¨ï¼ˆç”¨äºå­˜å‚¨å¼•æ“ï¼‰
            column_dicts = []
            for col_tuple in columns:
                if len(col_tuple) >= 2:
                    col_dict = {
                        'name': col_tuple[0],
                        'type': col_tuple[1],
                        'constraints': col_tuple[2] if len(col_tuple) > 2 else None
                    }
                    column_dicts.append(col_dict)
                    print(f"DEBUG: Column tuple: {col_tuple} -> Column dict: {col_dict}")

            # æ·»åŠ åˆ°å­˜å‚¨å¼•æ“
            self.storage_engine.create_table(table_name, column_dicts)
            return f"Table {table_name} created successfully"
        except Exception as e:
            raise SemanticError(f"åˆ›å»ºè¡¨é”™è¯¯: {str(e)}")

    # execution_engine.py ä¸­çš„ execute_insert æ–¹æ³•
    def execute_insert(self, table_name: str, columns: List[str], values: List[Any]) -> str:
        """æ‰§è¡ŒINSERTè¯­å¥"""
        try:
            # è·å–è¡¨schema
            schema = self.catalog.get_table_schema(table_name)
            if schema is None:
                raise SemanticError(f"Table '{table_name}' schema not found")

            # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°schemaä¿¡æ¯
            print(f"DEBUG: Table schema from catalog: {schema}")

            # æ„å»ºè¡Œæ•°æ®å­—å…¸
            row_data = {}
            column_names = [col_info[0] for col_info in schema]  # ä» tuple ä¸­æå–åˆ—å

            if columns:  # æŒ‡å®šäº†åˆ—å
                for i, col_name in enumerate(columns):
                    if i < len(values):
                        value = self._extract_value(values[i], table_name)
                        # ä»catalogè·å–ç±»å‹ä¿¡æ¯
                        col_info = self.catalog.get_column_info(table_name, col_name)
                        print(f"DEBUG: Column info for '{col_name}': {col_info}")

                        if col_info:
                            expected_type = col_info.get('type')
                            print(
                                f"DEBUG: Column '{col_name}' - expected: {expected_type}, actual: {type(value).__name__}")

                            # è¿›è¡Œç±»å‹æ£€æŸ¥
                            if expected_type and not self._is_type_compatible(type(value).__name__, expected_type):
                                # æ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                                raise SemanticError(
                                    f"åˆ— '{col_name}' ç±»å‹ä¸å…¼å®¹: æœŸæœ› {expected_type}, å¾—åˆ° {type(value).__name__}ã€‚"
                                    f"å€¼: {value} (ç±»å‹: {type(value).__name__})")

                        row_data[col_name] = value
            else:  # æœªæŒ‡å®šåˆ—åï¼ŒæŒ‰é¡ºåºæ’å…¥æ‰€æœ‰å€¼
                for i, value_expr in enumerate(values):
                    if i < len(column_names):
                        col_name = column_names[i]
                        value = self._extract_value(value_expr, table_name)
                        # ä»catalogè·å–ç±»å‹ä¿¡æ¯
                        col_info = self.catalog.get_column_info(table_name, col_name)
                        if col_info:
                            expected_type = col_info.get('type')
                            print(
                                f"DEBUG: Column '{col_name}' (index {i}) - expected: {expected_type}, actual: {type(value).__name__}")

                            # è¿›è¡Œç±»å‹æ£€æŸ¥
                            if expected_type and not self._is_type_compatible(type(value).__name__, expected_type):
                                # æ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                                raise SemanticError(
                                    f"åˆ— '{col_name}' ç±»å‹ä¸å…¼å®¹: æœŸæœ› {expected_type}, å¾—åˆ° {type(value).__name__}ã€‚"
                                    f"å€¼: {value} (ç±»å‹: {type(value).__name__})")

                        row_data[col_name] = value

            # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼ï¼Œç¼ºå¤±çš„å­—æ®µè®¾ä¸ºNone
            values_list = []
            for col_name in column_names:
                if col_name in row_data:
                    values_list.append(row_data[col_name])
                else:
                    values_list.append(None)  # è®¾ç½®é»˜è®¤å€¼

            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"DEBUG: Final values list for insertion: {values_list}")
            print(f"DEBUG: Column names: {column_names}")

            # æ·»åŠ äº‹åŠ¡æ”¯æŒ
            if self.current_transaction_id is not None and self.transaction_manager is not None:
                # åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œæ’å…¥
                success = self.storage_engine.insert_row_transactional(
                    table_name, values_list, self.current_transaction_id
                )
                if not success:
                    raise SemanticError("Failed to insert row in transaction")
            else:
                # éäº‹åŠ¡æ’å…¥
                self.storage_engine.insert_row(table_name, values_list)

            return "1 row inserted"
        except Exception as e:
            raise SemanticError(f"æ’å…¥è¡Œé”™è¯¯: {str(e)}")

    # execution_engine.py ä¸­çš„ execute_seq_scan æ–¹æ³•
    def execute_seq_scan(self, table_name: str) -> List[Dict]:
        """æ‰§è¡Œé¡ºåºæ‰«æ - æ·»åŠ è§†å›¾æ”¯æŒ"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯è§†å›¾
            if table_name in self.views:
                # è¿™æ˜¯è§†å›¾ï¼Œæ‰§è¡Œè§†å›¾å®šä¹‰
                view_info = self.views[table_name]
                if 'plan' in view_info:
                    # æ‰§è¡Œè§†å›¾çš„SELECTè®¡åˆ’
                    results = list(self.execute_plan(view_info['plan']))
                    # å¤„ç†åˆ—æ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰
                    if view_info.get('columns'):
                        mapped_results = []
                        for row in results:
                            mapped_row = {}
                            for i, col_name in enumerate(view_info['columns']):
                                if i < len(row):
                                    original_keys = list(row.keys())
                                    if i < len(original_keys):
                                        mapped_row[col_name] = row[original_keys[i]]
                            mapped_results.append(mapped_row)
                        return mapped_results
                    return results
                else:
                    # å›é€€åˆ°ç›´æ¥ä½¿ç”¨è§†å›¾å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
                    return view_info.get('definition', [])
            else:
                # æ™®é€šè¡¨ï¼Œä»å­˜å‚¨å¼•æ“è·å–æ•°æ®
                try:
                    return self.storage_engine.get_all_rows(table_name)
                except Exception as e:
                    # å¦‚æœè¡¨ä¸å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å¤§å°å†™é—®é¢˜
                    if "not found" in str(e).lower():
                        # å°è¯•æŸ¥æ‰¾å¯èƒ½çš„å¤§å°å†™å˜ä½“
                        all_tables = self.catalog.get_all_tables()
                        matching_tables = [t for t in all_tables if t.lower() == table_name.lower()]

                        if matching_tables:
                            # ä½¿ç”¨æ­£ç¡®å¤§å°å†™çš„è¡¨åé‡è¯•
                            correct_name = matching_tables[0]
                            self.logger.warning(f"Table '{table_name}' not found, using '{correct_name}' instead")
                            return self.storage_engine.get_all_rows(correct_name)

                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œé‡æ–°æŠ›å‡ºå¼‚å¸¸
                    raise SemanticError(f"æ‰«æè¡¨ {table_name} é”™è¯¯: {str(e)}")
        except Exception as e:
            raise SemanticError(f"æ‰«æè¡¨/è§†å›¾ {table_name} é”™è¯¯: {str(e)}")

    def execute_filter(self, condition: Any, child_plan: Operator) -> List[Dict]:
        """æ‰§è¡Œè¿‡æ»¤æ“ä½œ"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’
            child_results = list(self.execute_plan(child_plan))

            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            filtered_results = []
            for row in child_results:
                if self.evaluate_condition(row, condition):
                    filtered_results.append(row)

            return filtered_results
        except Exception as e:
            raise SemanticError(f"åº”ç”¨è¿‡æ»¤æ¡ä»¶é”™è¯¯: {str(e)}")

    def execute_project(self, columns: List[str], child_plan: Operator) -> List[Dict]:
        """æ‰§è¡ŒæŠ•å½±æ“ä½œ"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’
            child_results = list(self.execute_plan(child_plan))
            print(f"DEBUG: Project - Input rows: {len(child_results)}")
            print(f"DEBUG: Project - Columns to select: {columns}")

            if child_results:
                print(f"DEBUG: Project - First input row keys: {list(child_results[0].keys())}")
                print(f"DEBUG: Project - First input row values: {child_results[0]}")

            # åº”ç”¨æŠ•å½±
            projected_results = []
            for row in child_results:
                projected_row = {}
                for col in columns:
                    # å¤„ç†èšåˆå‡½æ•°åˆ—ï¼ˆå¦‚ COUNT(*), SUM(age) ç­‰ï¼‰
                    if '(' in col and ')' in col:
                        # è¿™æ˜¯èšåˆå‡½æ•°åˆ—ï¼Œåº”è¯¥å·²ç»åœ¨åˆ†ç»„é˜¶æ®µè®¡ç®—å¥½äº†
                        # ç›´æ¥ä»ç»“æœè¡Œä¸­è·å–
                        if col in row:
                            projected_row[col] = row[col]
                        else:
                            # å°è¯•æŸ¥æ‰¾ç±»ä¼¼çš„èšåˆåˆ—ï¼ˆå¤„ç†å¤§å°å†™æˆ–æ ¼å¼å·®å¼‚ï¼‰
                            matching_keys = [key for key in row.keys() if key.upper() == col.upper()]
                            if matching_keys:
                                projected_row[col] = row[matching_keys[0]]
                            else:
                                # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œä¿æŒåŸæ ·ï¼ˆå¯èƒ½æ˜¯æ™®é€šåˆ—ååŒ…å«æ‹¬å·ï¼‰
                                projected_row[col] = row.get(col, None)

                    # å¤„ç†æ™®é€šåˆ—å
                    elif col in row:
                        projected_row[col] = row[col]
                    elif col == '*':  # é€‰æ‹©æ‰€æœ‰åˆ—
                        projected_row = row.copy()
                        break
                    else:
                        # å¤„ç†å¸¦è¡¨åˆ«åçš„åˆ—å
                        if '.' in col:
                            table_alias, column_name = col.split('.', 1)
                            # æŸ¥æ‰¾åŒ¹é…çš„åˆ—
                            found = False
                            for key in row.keys():
                                if key == col:  # å®Œå…¨åŒ¹é… table.column
                                    projected_row[col] = row[key]
                                    found = True
                                    break
                                elif key.endswith('.' + column_name):  # éƒ¨åˆ†åŒ¹é…
                                    projected_row[col] = row[key]
                                    found = True
                                    break
                            if not found:
                                projected_row[col] = None
                        else:
                            projected_row[col] = None

                projected_results.append(projected_row)
                print(f"DEBUG: Project - Output row: {projected_row}")

            print(f"DEBUG: Project - Final results: {len(projected_results)} rows")
            return projected_results

        except Exception as e:
            print(f"DEBUG: Project - Error: {e}")
            raise SemanticError(f"åº”ç”¨æŠ•å½±é”™è¯¯: {str(e)}")

    def execute_update(self, table_name: str, assignments: List[tuple], child_plan: Operator) -> str:
        """æ‰§è¡ŒUPDATEè¯­å¥"""
        try:
            # æ£€æŸ¥äº‹åŠ¡çŠ¶æ€
            if self.current_transaction_id is None:
                self.logger.warning("No active transaction for UPDATE operation, auto-starting one")
                self.begin_transaction()

            txn_status = self.get_transaction_status()
            self.logger.debug(f"Transaction status before UPDATE: {txn_status}")

            # è®¾ç½®ç±»å‹æ£€æŸ¥å™¨çš„ä¸Šä¸‹æ–‡è¡¨
            self.type_checker.set_context_table(table_name)

            # å…ˆæ‰§è¡Œå­è®¡åˆ’è·å–è¦æ›´æ–°çš„è¡Œ
            rows_to_update = list(self.execute_plan(child_plan))
            self.logger.debug(f"Found {len(rows_to_update)} rows to update")

            # åº”ç”¨æ›´æ–°æ“ä½œ
            updated_count = 0
            for i, row in enumerate(rows_to_update):
                self.logger.debug(f"Processing row {i}: {row}")

                # æ„å»ºæ›´æ–°æ•°æ®
                update_data = {}
                for col_name, value_expr in assignments:
                    # è®¡ç®—è¡¨è¾¾å¼çš„å€¼ï¼ˆéœ€è¦ä¼ å…¥å½“å‰è¡Œçš„ä¸Šä¸‹æ–‡ï¼‰
                    value = self._evaluate_expression(value_expr, row, table_name)
                    self.logger.debug(f"Assignment {col_name} = {value} (from expression {value_expr})")

                    # ç±»å‹æ£€æŸ¥
                    expected_type = self.symbol_table.get_column_type(table_name, col_name)
                    if expected_type and not self._is_type_compatible(type(value).__name__.upper(), expected_type):
                        raise SemanticError(
                            f"åˆ— '{col_name}' ç±»å‹ä¸å…¼å®¹: æœŸæœ› {expected_type}, å¾—åˆ° {type(value).__name__}")
                    update_data[col_name] = value

                self.logger.debug(f"Update data: {update_data}")

                # æ·»åŠ äº‹åŠ¡æ”¯æŒ
                if self.current_transaction_id is not None and self.transaction_manager is not None:
                    # åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œæ›´æ–°
                    success = self.storage_engine.update_row_transactional(
                        table_name, row, update_data, self.current_transaction_id
                    )
                    if not success:
                        self.logger.error(f"Failed to update row in transaction {self.current_transaction_id}")
                        # å°è¯•è·å–æ›´å¤šé”™è¯¯ä¿¡æ¯
                        txn_status = self.get_transaction_status()
                        self.logger.error(f"Transaction status after failure: {txn_status}")
                        raise SemanticError("Failed to update row in transaction")
                else:
                    # éäº‹åŠ¡æ›´æ–°
                    self.storage_engine.update_row(table_name, row, update_data)
                updated_count += 1

            return f"{updated_count} rows updated"
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ•°æ®é”™è¯¯: {str(e)}")
            raise SemanticError(f"æ›´æ–°æ•°æ®é”™è¯¯: {str(e)}")

    def execute_delete(self, table_name: str, child_plan: Operator) -> str:
        """æ‰§è¡ŒDELETEè¯­å¥"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’è·å–è¦åˆ é™¤çš„è¡Œ
            rows_to_delete = list(self.execute_plan(child_plan))

            # æ‰§è¡Œåˆ é™¤æ“ä½œ
            deleted_count = 0
            for row in rows_to_delete:
                # æ·»åŠ äº‹åŠ¡æ”¯æŒ
                if self.current_transaction_id is not None and self.transaction_manager is not None:
                    # åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œåˆ é™¤
                    success = self.storage_engine.delete_row_transactional(
                        table_name, row, self.current_transaction_id
                    )
                    if not success:
                        raise SemanticError("Failed to delete row in transaction")
                else:
                    # éäº‹åŠ¡åˆ é™¤
                    self.storage_engine.delete_row(table_name, row)
                deleted_count += 1

            return f"{deleted_count} rows deleted"
        except Exception as e:
            raise SemanticError(f"åˆ é™¤æ•°æ®é”™è¯¯: {str(e)}")

    def evaluate_condition(self, row: Dict, condition: Any) -> bool:
        """è¯„ä¼°WHEREæ¡ä»¶"""
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"DEBUG: Evaluating condition: {condition} on row: {row}")

        # å¯¹äºHAVINGæ¡ä»¶ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†èšåˆå‡½æ•°
        if hasattr(condition, 'to_dict'):
            condition_dict = condition.to_dict()
            print(f"DEBUG: Condition dict: {condition_dict}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯HAVINGæ¡ä»¶ï¼ˆåŒ…å«èšåˆå‡½æ•°ï¼‰
            if self._is_having_condition(condition_dict):
                result = self._evaluate_having_condition(row, condition_dict)
                print(f"DEBUG: HAVING condition evaluation result: {result}")
                return result
            else:
                result = self._evaluate_condition_from_dict(row, condition_dict)
                print(f"DEBUG: Condition evaluation result: {result}")
                return result
        elif isinstance(condition, dict):
            print(f"DEBUG: Condition dict: {condition}")
            if self._is_having_condition(condition):
                result = self._evaluate_having_condition(row, condition)
                print(f"DEBUG: HAVING condition evaluation result: {result}")
                return result
            else:
                result = self._evaluate_condition_from_dict(row, condition)
                print(f"DEBUG: Condition evaluation result: {result}")
                return result
        else:
            # é»˜è®¤è¿”å›Trueï¼Œå®é™…åº”è¯¥æ ¹æ®æ¡ä»¶ç±»å‹è¿›è¡Œè§£æ
            print(f"DEBUG: Unknown condition type, returning True")
            return True

    def _is_having_condition(self, condition_dict: Dict) -> bool:
        """æ£€æŸ¥æ¡ä»¶æ˜¯å¦åŒ…å«èšåˆå‡½æ•°ï¼ˆHAVINGæ¡ä»¶ï¼‰"""
        if not condition_dict:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å«èšåˆå‡½æ•°
        def _contains_aggregate(expr):
            if not isinstance(expr, dict):
                return False

            if expr.get('type') == 'FunctionExpr':
                func_name = expr.get('function_name', '').upper()
                if func_name in ['AVG', 'SUM', 'COUNT', 'MAX', 'MIN']:
                    return True

            # é€’å½’æ£€æŸ¥å­è¡¨è¾¾å¼
            for key, value in expr.items():
                if isinstance(value, dict):
                    if _contains_aggregate(value):
                        return True
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, dict) and _contains_aggregate(item):
                            return True

            return False

        return _contains_aggregate(condition_dict)

    def _evaluate_having_condition(self, row: Dict, condition: Dict) -> bool:
        """ä¸“é—¨å¤„ç†HAVINGæ¡ä»¶ï¼ˆåŒ…å«èšåˆå‡½æ•°ï¼‰"""
        # HAVINGæ¡ä»¶åº”è¯¥åœ¨åˆ†ç»„ç»“æœä¸­ç›´æ¥ä½¿ç”¨å·²ç»è®¡ç®—å¥½çš„èšåˆå€¼
        # è€Œä¸æ˜¯é‡æ–°è®¡ç®—èšåˆå‡½æ•°

        condition_type = condition.get('type')

        if condition_type == 'BinaryExpr':
            left = condition.get('left', {})
            right = condition.get('right', {})
            operator = condition.get('operator', '')

            # å¯¹äºHAVINGæ¡ä»¶ï¼Œç›´æ¥è·å–å·¦å³è¡¨è¾¾å¼çš„å€¼ï¼ˆè€Œä¸æ˜¯é‡æ–°è®¡ç®—ï¼‰
            left_value = self._get_value_for_having(row, left)
            right_value = self._get_value_for_having(row, right)

            # å¤„ç†Noneå€¼
            if left_value is None or right_value is None:
                return False

            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(
                f"DEBUG: HAVING BinaryExpr - left_value: {left_value}, right_value: {right_value}, operator: {operator}")

            if operator == '=':
                return left_value == right_value
            elif operator == '!=' or operator == '<>':
                return left_value != right_value
            elif operator == '>':
                return left_value > right_value
            elif operator == '>=':
                return left_value >= right_value
            elif operator == '<':
                return left_value < right_value
            elif operator == '<=':
                return left_value <= right_value

        # å¯¹äºå…¶ä»–ç±»å‹çš„æ¡ä»¶ï¼Œä½¿ç”¨æ™®é€šçš„è¯„ä¼°é€»è¾‘
        return self._evaluate_condition_from_dict(row, condition)

    def _get_value_for_having(self, row: Dict, expr: Dict) -> Any:
        """ä¸ºHAVINGæ¡ä»¶è·å–å€¼ï¼ˆä¼˜å…ˆä½¿ç”¨åˆ†ç»„ç»“æœä¸­çš„å€¼ï¼‰"""
        expr_type = expr.get('type')

        if expr_type == 'FunctionExpr':
            # å¯¹äºèšåˆå‡½æ•°ï¼Œå°è¯•ä»ç»“æœè¡Œä¸­æŸ¥æ‰¾å¯¹åº”çš„åˆ—
            func_name = expr.get('function_name', '').upper()
            args = expr.get('arguments', [])

            # æ„å»ºèšåˆå‡½æ•°åˆ—åï¼ˆä¸åˆ†ç»„ç»“æœä¸­çš„åˆ—åæ ¼å¼ä¸€è‡´ï¼‰
            if args and len(args) == 1 and args[0].get('type') == 'LiteralExpr' and args[0].get('value') == '*':
                column_name = f"{func_name}(*)"
            elif args:
                # å¤„ç†æœ‰å‚æ•°çš„å‡½æ•°
                arg_values = []
                for arg in args:
                    if arg.get('type') == 'IdentifierExpr':
                        arg_values.append(arg.get('name'))
                    elif arg.get('type') == 'LiteralExpr':
                        arg_values.append(str(arg.get('value')))
                    else:
                        arg_values.append('?')
                column_name = f"{func_name}({', '.join(arg_values)})"
            else:
                column_name = f"{func_name}()"

            # é¦–å…ˆå°è¯•ä»ç»“æœè¡Œä¸­è·å–å·²ç»è®¡ç®—å¥½çš„èšåˆå€¼
            if column_name in row:
                return row[column_name]

            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—åæ ¼å¼
            possible_keys = [key for key in row.keys() if key.startswith(func_name + '(')]
            if possible_keys:
                return row[possible_keys[0]]

            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå›é€€åˆ°æ™®é€šè®¡ç®—ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼‰
            return self._evaluate_function(func_name, args, row)

        elif expr_type == 'LiteralExpr':
            return expr.get('value')

        elif expr_type == 'IdentifierExpr':
            column_name = expr.get('name')
            # ç›´æ¥ä½¿ç”¨åˆ†ç»„ç»“æœä¸­çš„å€¼
            return row.get(column_name)

        # å…¶ä»–ç±»å‹çš„è¡¨è¾¾å¼ä½¿ç”¨æ™®é€šé€»è¾‘
        return self._get_value_from_condition(row, expr)

    def _evaluate_condition_from_dict(self, row: Dict, condition: Dict) -> bool:
        """ä»å­—å…¸å½¢å¼è¯„ä¼°æ¡ä»¶"""
        condition_type = condition.get('type')

        if condition_type == 'BinaryExpr':
            left = condition.get('left', {})
            right = condition.get('right', {})
            operator = condition.get('operator', '')

            if operator in ['AND', 'OR']:
                left_result = self._evaluate_condition_from_dict(row, left)
                right_result = self._evaluate_condition_from_dict(row, right)

                if operator == 'AND':
                    return left_result and right_result
                elif operator == 'OR':
                    return left_result or right_result
            else:
                # å¯¹äºæ¯”è¾ƒæ“ä½œç¬¦ï¼Œéœ€è¦è·å–å®é™…å€¼è¿›è¡Œæ¯”è¾ƒ
                left_value = self._get_value_from_condition(row, left)
                right_value = self._get_value_from_condition(row, right)

                # å¤„ç†Noneå€¼
                if left_value is None or right_value is None:
                    return False

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                print(f"DEBUG: BinaryExpr - left_value: {left_value}, right_value: {right_value}, operator: {operator}")

                if operator == '=':
                    return left_value == right_value
                elif operator == '!=' or operator == '<>':
                    return left_value != right_value
                elif operator == '>':
                    return left_value > right_value
                elif operator == '>=':
                    return left_value >= right_value
                elif operator == '<':
                    return left_value < right_value
                elif operator == '<=':
                    return left_value <= right_value

        elif condition_type == 'IdentifierExpr':
            column_name = condition.get('name')
            table_name = condition.get('table_name')

            # å¤„ç†èšåˆå‡½æ•°åˆ—åï¼ˆå¦‚ "AVG(age)"ï¼‰
            if '(' in column_name and ')' in column_name:
                # è¿™æ˜¯èšåˆå‡½æ•°åˆ—ï¼Œç›´æ¥ä»ç»“æœè¡Œä¸­è·å–
                if column_name in row:
                    return bool(row[column_name])
                return False

            # å¦‚æœæŒ‡å®šäº†è¡¨åï¼Œæ£€æŸ¥æ ¼å¼æ˜¯å¦ä¸º table.column
            if table_name:
                full_column_name = f"{table_name}.{column_name}"
                if full_column_name in row:
                    return bool(row[full_column_name])
                return False

            # ç›´æ¥ä½¿ç”¨åˆ—å
            if column_name in row:
                return bool(row[column_name])
            return False

        elif condition_type == 'LiteralExpr':
            value = condition.get('value')
            return bool(value)

        elif condition_type == 'UnaryExpr':
            operator = condition.get('operator')
            operand = condition.get('operand', {})
            operand_value = self._evaluate_condition_from_dict(row, operand)

            if operator == 'NOT':
                return not operand_value

        elif condition_type == 'FunctionExpr':
            # å¤„ç†å‡½æ•°è¡¨è¾¾å¼
            func_name = condition.get('function_name', '').upper()
            args = condition.get('arguments', [])
            return self._evaluate_function(func_name, args, row)

        elif condition_type == 'InExpr':
            # å¤„ç†INè¡¨è¾¾å¼
            left_expr = condition.get('left_expr', {})
            right_expr = condition.get('right_expr', {})
            is_not = condition.get('is_not', False)

            left_value = self._get_value_from_condition(row, left_expr)
            right_value = self._get_value_from_condition(row, right_expr)

            # å¤„ç†å­æŸ¥è¯¢ç»“æœï¼ˆåº”è¯¥æ˜¯åˆ—è¡¨ï¼‰
            if isinstance(right_value, list):
                result = left_value in right_value
                return not result if is_not else result
            elif isinstance(right_value, (str, int, float, bool)):
                # å¤„ç†å­—é¢å€¼æ¯”è¾ƒ
                result = left_value == right_value
                return not result if is_not else result
            return False

        elif condition_type == 'SubqueryExpr':
            # å¤„ç†å­æŸ¥è¯¢è¡¨è¾¾å¼
            subquery_result = self._evaluate_subquery_expression(row, condition)
            # å­æŸ¥è¯¢åº”è¯¥è¿”å›ä¸€ä¸ªå€¼åˆ—è¡¨ï¼Œç”¨äºINæ“ä½œ
            return bool(subquery_result)

        return True

    def _evaluate_function(self, func_name: str, args: List[Dict], row: Dict) -> Any:
        """è¯„ä¼°å‡½æ•°è°ƒç”¨"""
        # æå–å‚æ•°å€¼
        arg_values = [self._get_value_from_condition(row, arg) for arg in args]

        if func_name == 'COUNT':
            return len([v for v in arg_values if v is not None])
        elif func_name == 'SUM':
            return sum([v for v in arg_values if isinstance(v, (int, float))])
        elif func_name == 'AVG':
            values = [v for v in arg_values if isinstance(v, (int, float))]
            return sum(values) / len(values) if values else 0
        elif func_name == 'MAX':
            values = [v for v in arg_values if isinstance(v, (int, float))]
            return max(values) if values else None
        elif func_name == 'MIN':
            values = [v for v in arg_values if isinstance(v, (int, float))]
            return min(values) if values else None
        else:
            return None

    def _get_value_from_condition(self, row: Dict, condition: Dict) -> Any:
        """ä»æ¡ä»¶å­—å…¸ä¸­è·å–å®é™…å€¼"""
        condition_type = condition.get('type')

        if condition_type == 'IdentifierExpr':
            column_name = condition.get('name')
            table_name = condition.get('table_name')

            # å¤„ç†å¸¦è¡¨åˆ«åçš„æƒ…å†µ
            if table_name:
                full_column_name = f"{table_name}.{column_name}"

                # é¦–å…ˆå°è¯•æŸ¥æ‰¾å¸¦è¡¨åˆ«åçš„åˆ—
                if full_column_name in row:
                    return row[full_column_name]

                # å¦‚æœæ‰¾ä¸åˆ°å¸¦è¡¨åˆ«åçš„åˆ—ï¼Œå°è¯•åªç”¨åˆ—å
                # è¿™åœ¨JOINåçš„ç»“æœä¸­æ˜¯å¸¸è§çš„ï¼Œå› ä¸ºåˆ—åå¯èƒ½ä¼šè¢«åˆå¹¶
                if column_name in row:
                    return row[column_name]

                return None

            # ç›´æ¥ä½¿ç”¨åˆ—åï¼ˆæ²¡æœ‰è¡¨åˆ«åçš„æƒ…å†µï¼‰
            return row.get(column_name)

        elif condition_type == 'LiteralExpr':
            return condition.get('value')

        elif condition_type == 'BinaryExpr':
            # å¯¹äºäºŒå…ƒè¡¨è¾¾å¼ï¼Œé€’å½’è®¡ç®—å€¼
            left = self._get_value_from_condition(row, condition.get('left', {}))
            right = self._get_value_from_condition(row, condition.get('right', {}))
            operator = condition.get('operator', '')

            # æ›´ç²¾ç¡®çš„ NULL å€¼å¤„ç†
            # åªæœ‰å½“ä¸€ä¸ªæ“ä½œæ•°æ˜¯ NULL æ—¶æ‰è¿”å› NULL
            if left is None or right is None:
                # å¯¹äºç®—æœ¯è¿ç®—ï¼Œå¦‚æœä»»ä¸€æ“ä½œæ•°ä¸º NULLï¼Œç»“æœä¸º NULL
                if operator in ['+', '-', '*', '/']:
                    return None
                # å¯¹äºæ¯”è¾ƒè¿ç®—ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆä½†è¿™é‡Œä¸»è¦æ˜¯å¤„ç†ç®—æœ¯è¿ç®—ï¼‰
                return None

            if operator == '+':
                return left + right
            elif operator == '-':
                return left - right
            elif operator == '*':
                return left * right
            elif operator == '/':
                return left / right if right != 0 else None  # é™¤é›¶ä¹Ÿè¿”å› None

        elif condition_type == 'FunctionExpr':
            # å¤„ç†å‡½æ•°è¡¨è¾¾å¼
            func_name = condition.get('function_name', '').upper()
            args = condition.get('arguments', [])
            return self._evaluate_function(func_name, args, row)

        elif condition_type == 'ValueListExpr':
            # å¤„ç†å€¼åˆ—è¡¨
            values = condition.get('values', [])
            return [self._get_value_from_condition(row, val) for val in values]

        elif condition_type == 'SubqueryExpr':
            # å¤„ç†å­æŸ¥è¯¢è¡¨è¾¾å¼
            return self._evaluate_subquery_expression(row, condition)

        # é»˜è®¤è¿”å›None
        return None

    # execution_engine.py ä¸­çš„ _extract_value æ–¹æ³•
    def _extract_value(self, value_expr: Any, context_table: str = None) -> Any:
        """ä»è¡¨è¾¾å¼èŠ‚ç‚¹ä¸­æå–å€¼"""
        # è®¾ç½®ç±»å‹æ£€æŸ¥å™¨çš„ä¸Šä¸‹æ–‡è¡¨
        if context_table:
            self.type_checker.set_context_table(context_table)

        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        print(f"DEBUG: Extracting value from: {value_expr}, type: {type(value_expr)}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯å­—é¢é‡è¡¨è¾¾å¼èŠ‚ç‚¹
        if hasattr(value_expr, 'to_dict'):
            expr_dict = value_expr.to_dict()
            print(f"DEBUG: Expression dict: {expr_dict}")

            # å¦‚æœæ˜¯å­—é¢é‡è¡¨è¾¾å¼ï¼Œç›´æ¥è¿”å›value
            if expr_dict.get('type') == 'LiteralExpr':
                value = expr_dict.get('value')
                print(f"DEBUG: Extracted literal value: {value}, type: {type(value).__name__}")
                return value

        # å¦‚æœæ˜¯åŸºæœ¬æ•°æ®ç±»å‹ï¼Œç›´æ¥è¿”å›
        elif isinstance(value_expr, (int, float, str, bool)):
            print(f"DEBUG: Extracted basic value: {value_expr}, type: {type(value_expr).__name__}")
            return value_expr

        # æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
        elif hasattr(value_expr, 'value'):
            value = value_expr.value
            print(f"DEBUG: Extracted value from .value attribute: {value}, type: {type(value).__name__}")
            return value

        else:
            print(f"DEBUG: Unknown value_expr type: {type(value_expr)}, repr: {repr(value_expr)}")
            # å°è¯•ç›´æ¥è®¿é—®å¯èƒ½çš„å€¼å±æ€§
            for attr in ['value', 'val', 'data']:
                if hasattr(value_expr, attr):
                    value = getattr(value_expr, attr)
                    print(f"DEBUG: Found value in {attr}: {value}")
                    return value

        return None

    def _extract_value_from_dict(self, expr_dict: Dict) -> Any:
        """ä»è¡¨è¾¾å¼å­—å…¸ä¸­æå–å€¼"""
        expr_type = expr_dict.get('type')

        if expr_type == 'LiteralExpr':
            return expr_dict.get('value')
        elif expr_type == 'IdentifierExpr':
            # åˆ—å¼•ç”¨ï¼Œæ— æ³•ç›´æ¥è·å–å€¼
            return None
        elif expr_type == 'BinaryExpr':
            # å¯¹äºäºŒå…ƒè¡¨è¾¾å¼ï¼Œé€’å½’è®¡ç®—å€¼
            left = self._extract_value_from_dict(expr_dict.get('left', {}))
            right = self._extract_value_from_dict(expr_dict.get('right', {}))
            operator = expr_dict.get('operator', '')

            if operator == '+':
                return left + right
            elif operator == '-':
                return left - right
            elif operator == '*':
                return left * right
            elif operator == '/':
                return left / right if right != 0 else 0
        elif expr_type == 'FunctionExpr':
            # å¤„ç†å‡½æ•°è¡¨è¾¾å¼
            func_name = expr_dict.get('function_name', '').upper()
            args = expr_dict.get('arguments', [])
            arg_values = [self._extract_value_from_dict(arg) for arg in args]

            if func_name == 'COUNT':
                return len([v for v in arg_values if v is not None])
            elif func_name == 'SUM':
                return sum([v for v in arg_values if isinstance(v, (int, float))])
            elif func_name == 'AVG':
                values = [v for v in arg_values if isinstance(v, (int, float))]
                return sum(values) / len(values) if values else 0
            elif func_name == 'MAX':
                values = [v for v in arg_values if isinstance(v, (int, float))]
                return max(values) if values else None
            elif func_name == 'MIN':
                values = [v for v in arg_values if isinstance(v, (int, float))]
                return min(values) if values else None

        return None

    def execute_optimized_seq_scan(self, table_name: str, selected_columns: List[str]) -> List[Dict]:
        """æ‰§è¡Œä¼˜åŒ–çš„é¡ºåºæ‰«æï¼ˆåŒ…å«æŠ•å½±ä¸‹æ¨ï¼‰- æ·»åŠ è§†å›¾æ”¯æŒ"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯è§†å›¾
            if table_name in self.views:
                # è¿™æ˜¯è§†å›¾ï¼Œæ‰§è¡Œè§†å›¾å®šä¹‰
                view_info = self.views[table_name]
                if 'plan' in view_info:
                    # æ‰§è¡Œè§†å›¾çš„SELECTè®¡åˆ’
                    view_results = list(self.execute_plan(view_info['plan']))

                    # åº”ç”¨æŠ•å½±ï¼šåªé€‰æ‹©æŒ‡å®šçš„åˆ—
                    projected_rows = []
                    for row in view_results:
                        projected_row = {}
                        for col in selected_columns:
                            if col in row:
                                projected_row[col] = row[col]
                            # å¤„ç†é€šé…ç¬¦ *
                            elif col == '*':
                                projected_row = row.copy()
                                break
                        projected_rows.append(projected_row)

                    return projected_rows
                else:
                    # å›é€€åˆ°ç›´æ¥ä½¿ç”¨è§†å›¾å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
                    view_data = view_info.get('definition', [])

                    # åº”ç”¨æŠ•å½±
                    projected_rows = []
                    for row in view_data:
                        projected_row = {}
                        for col in selected_columns:
                            if col in row:
                                projected_row[col] = row[col]
                            elif col == '*':
                                projected_row = row.copy()
                                break
                        projected_rows.append(projected_row)

                    return projected_rows
            else:
                # æ™®é€šè¡¨ï¼Œä»å­˜å‚¨å¼•æ“è·å–æ•°æ®
                all_rows = self.storage_engine.get_all_rows(table_name)

                # åº”ç”¨æŠ•å½±ï¼šåªé€‰æ‹©æŒ‡å®šçš„åˆ—
                projected_rows = []
                for row in all_rows:
                    projected_row = {}
                    for col in selected_columns:
                        if col in row:
                            projected_row[col] = row[col]
                        # å¤„ç†é€šé…ç¬¦ *
                        elif col == '*':
                            projected_row = row.copy()
                            break
                    projected_rows.append(projected_row)

                return projected_rows
        except Exception as e:
            raise SemanticError(f"æ‰«æè¡¨/è§†å›¾ {table_name} é”™è¯¯: {str(e)}")

    def execute_delete(self, table_name: str, child_plan: Operator) -> str:
        """æ‰§è¡ŒDELETEè¯­å¥"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’è·å–è¦åˆ é™¤çš„è¡Œ
            rows_to_delete = list(self.execute_plan(child_plan))

            # æ‰§è¡Œåˆ é™¤æ“ä½œ
            deleted_count = 0
            for row in rows_to_delete:
                self.storage_engine.delete_row(table_name, row)
                deleted_count += 1

            return f"{deleted_count} rows deleted"
        except Exception as e:
            raise SemanticError(f"åˆ é™¤æ•°æ®é”™è¯¯: {str(e)}")

    def _is_type_compatible(self, actual_python_type: str, expected_sql_type: str) -> bool:
        """æ£€æŸ¥ç±»å‹æ˜¯å¦å…¼å®¹"""
        # é¦–å…ˆæ¸…ç† expected_sql_typeï¼Œç§»é™¤é•¿åº¦ä¿¡æ¯
        # ä¾‹å¦‚ï¼šVARCHAR(50) -> VARCHAR, INT -> INT
        import re

        # æ¸…ç†æœŸæœ›çš„SQLç±»å‹ï¼ˆç§»é™¤æ‹¬å·å’Œé•¿åº¦ä¿¡æ¯ï¼‰
        cleaned_expected_type = re.sub(r'\(.*\)', '', expected_sql_type).upper()

        # Python ç±»å‹åˆ° SQL ç±»å‹çš„æ˜ å°„
        type_mapping = {
            'int': 'INT',
            'str': 'VARCHAR',
            'float': 'FLOAT',
            'bool': 'BOOLEAN'
        }

        # å°† Python ç±»å‹è½¬æ¢ä¸ºå¯¹åº”çš„ SQL ç±»å‹
        actual_sql_type = type_mapping.get(actual_python_type.lower(), 'UNKNOWN')

        if actual_sql_type == "UNKNOWN" or cleaned_expected_type == "UNKNOWN":
            return True  # æœªçŸ¥ç±»å‹æš‚æ—¶å…è®¸

        # å®Œå…¨åŒ¹é…
        if actual_sql_type == cleaned_expected_type:
            return True

        # VARCHAR å’Œ CHAR å…¼å®¹
        if (actual_sql_type == "VARCHAR" and cleaned_expected_type == "CHAR") or \
                (actual_sql_type == "CHAR" and cleaned_expected_type == "VARCHAR"):
            return True

        # æ•°å€¼ç±»å‹å…¼å®¹
        numeric_types = {"INT", "NUMERIC", "FLOAT", "DOUBLE", "DECIMAL"}
        if actual_sql_type in numeric_types and cleaned_expected_type in numeric_types:
            return True

        # å­—ç¬¦ä¸²ç±»å‹å…¼å®¹ï¼ˆä»»ä½•Pythonå­—ç¬¦ä¸²éƒ½å¯ä»¥èµ‹å€¼ç»™VARCHARæˆ–CHARï¼‰
        if actual_sql_type == "VARCHAR" and cleaned_expected_type in ["VARCHAR", "CHAR", "TEXT"]:
            return True

        return False

    def _evaluate_expression(self, expr: Any, row: Dict, context_table: str = None) -> Any:
        """è®¡ç®—è¡¨è¾¾å¼çš„å€¼ï¼ˆè€ƒè™‘å½“å‰è¡Œçš„ä¸Šä¸‹æ–‡ï¼‰"""
        # è®¾ç½®ç±»å‹æ£€æŸ¥å™¨çš„ä¸Šä¸‹æ–‡è¡¨
        if context_table:
            self.type_checker.set_context_table(context_table)

        print(f"DEBUG: _evaluate_expression - expr: {expr}, row: {row}")

        # å¦‚æœè¡¨è¾¾å¼æœ‰ to_dict æ–¹æ³•ï¼Œè½¬æ¢ä¸ºå­—å…¸å½¢å¼
        if hasattr(expr, 'to_dict'):
            expr_dict = expr.to_dict()
            result = self._get_value_from_condition(row, expr_dict)
            print(f"DEBUG: _evaluate_expression result: {result}")
            return result

        # å¦‚æœæ˜¯å­—å…¸å½¢å¼ï¼Œç›´æ¥ä½¿ç”¨
        elif isinstance(expr, dict):
            result = self._get_value_from_condition(row, expr)
            print(f"DEBUG: _evaluate_expression result: {result}")
            return result

        # å¦‚æœæ˜¯åŸºæœ¬æ•°æ®ç±»å‹ï¼Œç›´æ¥è¿”å›
        elif isinstance(expr, (int, float, str, bool)):
            print(f"DEBUG: _evaluate_expression result: {expr}")
            return expr

        # å…¶ä»–æƒ…å†µå°è¯•æå–å€¼
        else:
            result = self._extract_value(expr, context_table)
            print(f"DEBUG: _evaluate_expression result: {result}")
            return result

    def execute_order_by(self, order_columns: List[Tuple[str, str]], child_plan: Operator) -> List[Dict]:
        """æ‰§è¡Œæ’åºæ“ä½œ"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’è·å–æ•°æ®
            child_results = list(self.execute_plan(child_plan))

            # å¦‚æœæ²¡æœ‰ç»“æœæˆ–æ²¡æœ‰æ’åºæ¡ä»¶ï¼Œç›´æ¥è¿”å›
            if not child_results or not order_columns:
                return child_results

            # æ„å»ºæ’åºé”®å‡½æ•°
            def get_sort_key(row):
                sort_key = []
                for column, direction in order_columns:
                    # å¤„ç†å¯èƒ½çš„ table.column æ ¼å¼
                    if '.' in column:
                        # å¦‚æœåˆ—ååŒ…å«è¡¨åï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾
                        if column in row:
                            value = row[column]
                        else:
                            # å°è¯•åˆ†å‰²è¡¨åå’Œåˆ—å
                            table_name, col_name = column.split('.', 1)
                            full_key = f"{table_name}.{col_name}"
                            value = row.get(full_key, row.get(col_name, None))
                    else:
                        value = row.get(column, None)

                    # å¤„ç†æ’åºæ–¹å‘
                    sort_key.append((value, direction.lower() == 'desc'))
                return sort_key

            # æ’åºå‡½æ•°
            def sort_rows(row):
                sort_key = get_sort_key(row)
                key_values = []
                for value, reverse in sort_key:
                    # å¤„ç†Noneå€¼ï¼Œå°†å…¶æ”¾åœ¨æœ€åï¼ˆæ— è®ºå‡åºé™åºï¼‰
                    if value is None:
                        # å¯¹äºé™åºï¼ŒNoneå€¼åº”è¯¥åœ¨æœ€å‰é¢ï¼Œä½†æˆ‘ä»¬ç»Ÿä¸€æ”¾åœ¨æœ€å
                        key_value = (0 if reverse else 1, '')  # ä½¿ç”¨ç‰¹æ®Šå€¼ç¡®ä¿Noneåœ¨æœ€å
                    else:
                        # å¯¹äºé™åºï¼Œä½¿ç”¨è´Ÿå€¼æˆ–åè½¬æ¯”è¾ƒ
                        if reverse:
                            # å¯¹äºæ•°å­—ï¼Œä½¿ç”¨è´Ÿå€¼ï¼›å¯¹äºå…¶ä»–ç±»å‹ï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†
                            if isinstance(value, (int, float)):
                                key_value = (-value, '')
                            else:
                                key_value = (1, str(value))  # é™åºæ—¶å­—ç¬¦ä¸²æ’åºéœ€è¦ç‰¹æ®Šå¤„ç†
                        else:
                            key_value = (0, value) if isinstance(value, (int, float)) else (1, str(value))
                    key_values.append(key_value)
                return tuple(key_values)

            # æ‰§è¡Œæ’åº
            sorted_results = sorted(child_results, key=sort_rows)

            return sorted_results

        except Exception as e:
            raise SemanticError(f"æ’åºæ“ä½œé”™è¯¯: {str(e)}")

    def execute_group_by(self, group_columns: List[str], having_condition: Optional[Any],
                         child_plan: Operator, aggregate_functions: List[tuple]) -> List[Dict]:
        """æ‰§è¡Œåˆ†ç»„æ“ä½œ"""
        try:
            # å…ˆæ‰§è¡Œå­è®¡åˆ’è·å–æ•°æ®
            child_results = list(self.execute_plan(child_plan))
            print(f"DEBUG: GroupBy - Child results: {child_results}")
            print(f"DEBUG: GroupBy - Group columns: {group_columns}")
            print(f"DEBUG: GroupBy - Aggregate functions: {aggregate_functions}")

            # å¦‚æœæ²¡æœ‰èšåˆå‡½æ•°ä½†æœ‰GROUP BYï¼Œéœ€è¦æ·»åŠ COUNT(*)
            if not aggregate_functions and group_columns:
                aggregate_functions = [('COUNT', '*')]
                print(f"DEBUG: GroupBy - Added default COUNT(*) aggregation")

            # åˆ†ç»„æ“ä½œ
            groups = {}
            for row in child_results:
                # æ„å»ºåˆ†ç»„é”®
                group_key_values = []
                for col in group_columns:
                    group_key_values.append(row.get(col, None))

                group_key = tuple(group_key_values)
                print(f"DEBUG: GroupBy - Row: {row}, Group key: {group_key}")

                if group_key not in groups:
                    groups[group_key] = []
                groups[group_key].append(row)

            print(f"DEBUG: GroupBy - Groups formed: {groups}")

            # åº”ç”¨èšåˆå‡½æ•°å¹¶æ„å»ºç»“æœ
            result_rows = []
            for group_key, group_rows in groups.items():
                print(f"DEBUG: GroupBy - Processing group: {group_key}, rows: {len(group_rows)}")

                # æ„å»ºåˆ†ç»„ç»“æœè¡Œ
                result_row = {}

                # æ·»åŠ åˆ†ç»„åˆ—
                for i, col in enumerate(group_columns):
                    result_row[col] = group_key[i]

                # è®¡ç®—æ‰€æœ‰èšåˆå‡½æ•°
                for func_name, column_name in aggregate_functions:
                    print(f"DEBUG: GroupBy - Calculating {func_name}({column_name})")

                    # åœ¨ execute_group_by æ–¹æ³•ä¸­ï¼Œä¿®æ”¹èšåˆåˆ—åçš„åˆ›å»ºæ–¹å¼
                    if func_name.upper() == 'COUNT':
                        if column_name == '*':
                            # COUNT(*) - è®¡ç®—æ‰€æœ‰è¡Œæ•°
                            result_row["COUNT(*)"] = len(group_rows)  # ä½¿ç”¨ "COUNT(*)" è€Œä¸æ˜¯ "COUNT(*)"
                            print(f"DEBUG: GroupBy - COUNT(*): {len(group_rows)}")
                        else:
                            # COUNT(column) - è®¡ç®—éç©ºå€¼æ•°é‡
                            values = [row.get(column_name) for row in group_rows if row.get(column_name) is not None]
                            result_row[f"COUNT({column_name})"] = len(values)  # ä½¿ç”¨ "COUNT(column)" æ ¼å¼
                            print(f"DEBUG: GroupBy - COUNT({column_name}): {len(values)}")

                    elif func_name.upper() == 'SUM':
                        # è®¡ç®—æ€»å’Œ
                        values = [row.get(column_name) for row in group_rows
                                  if
                                  row.get(column_name) is not None and isinstance(row.get(column_name), (int, float))]
                        sum_value = sum(values) if values else 0
                        result_row[f"SUM({column_name})"] = sum_value
                        print(f"DEBUG: GroupBy - SUM({column_name}): {sum_value}")

                    elif func_name.upper() == 'AVG':
                        # è®¡ç®—å¹³å‡å€¼
                        values = [row.get(column_name) for row in group_rows
                                  if
                                  row.get(column_name) is not None and isinstance(row.get(column_name), (int, float))]
                        print(f"DEBUG: GroupBy - AVG values: {values}")
                        if values:
                            avg_value = sum(values) / len(values)
                            result_row[f"AVG({column_name})"] = avg_value
                            print(f"DEBUG: GroupBy - AVG({column_name}): {avg_value}")
                        else:
                            result_row[f"AVG({column_name})"] = None
                            print(f"DEBUG: GroupBy - AVG({column_name}): None")

                    elif func_name.upper() == 'MAX':
                        # è®¡ç®—æœ€å¤§å€¼
                        values = [row.get(column_name) for row in group_rows
                                  if
                                  row.get(column_name) is not None and isinstance(row.get(column_name), (int, float))]
                        max_value = max(values) if values else None
                        result_row[f"MAX({column_name})"] = max_value
                        print(f"DEBUG: GroupBy - MAX({column_name}): {max_value}")

                    elif func_name.upper() == 'MIN':
                        # è®¡ç®—æœ€å°å€¼
                        values = [row.get(column_name) for row in group_rows
                                  if
                                  row.get(column_name) is not None and isinstance(row.get(column_name), (int, float))]
                        min_value = min(values) if values else None
                        result_row[f"MIN({column_name})"] = min_value
                        print(f"DEBUG: GroupBy - MIN({column_name}): {min_value}")

                print(f"DEBUG: GroupBy - Result row before HAVING: {result_row}")

                # åº”ç”¨ HAVING æ¡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
                if having_condition:
                    condition_result = self.evaluate_condition(result_row, having_condition)
                    print(f"DEBUG: GroupBy - HAVING condition result: {condition_result}")

                    if not condition_result:
                        print(f"DEBUG: GroupBy - Group filtered out by HAVING")
                        continue  # è·³è¿‡ä¸æ»¡è¶³ HAVING æ¡ä»¶çš„åˆ†ç»„

                result_rows.append(result_row)
                print(f"DEBUG: GroupBy - Added result row: {result_row}")

            print(f"DEBUG: GroupBy - Final result rows: {result_rows}")
            return result_rows

        except Exception as e:
            print(f"DEBUG: GroupBy - Error: {e}")
            raise SemanticError(f"åˆ†ç»„æ“ä½œé”™è¯¯: {str(e)}")

    def _evaluate_subquery_expression(self, row: Dict, subquery_expr: Dict) -> Any:
        """è¯„ä¼°å­æŸ¥è¯¢è¡¨è¾¾å¼"""
        try:
            # è·å–å­æŸ¥è¯¢çš„SELECTè¯­å¥
            select_stmt_dict = subquery_expr.get('select_stmt', {})

            # éœ€è¦å°†å­—å…¸å½¢å¼çš„SELECTè¯­å¥è½¬æ¢å›ASTèŠ‚ç‚¹
            from sql_compiler.parser.ast_nodes import SelectStmt, TableRef, IdentifierExpr, LiteralExpr, BinaryExpr
            from sql_compiler.codegen.plan_generator import PlanGenerator

            # æ„å»ºSELECTè¯­å¥ASTèŠ‚ç‚¹
            columns = select_stmt_dict.get('columns', [])
            from_clause_dict = select_stmt_dict.get('from_clause', {})
            where_clause_dict = select_stmt_dict.get('where_clause', {})

            # æ„å»ºFROMå­å¥
            if from_clause_dict.get('type') == 'TableRef':
                from_clause = TableRef(
                    from_clause_dict.get('table_name'),
                    from_clause_dict.get('alias')
                )
            else:
                # ç®€åŒ–å¤„ç†ï¼Œåªå¤„ç†å•è¡¨
                from_clause = TableRef(from_clause_dict.get('table_name', ''))

            # æ„å»ºWHEREå­å¥
            where_clause = None
            if where_clause_dict:
                if where_clause_dict.get('type') == 'BinaryExpr':
                    left_dict = where_clause_dict.get('left', {})
                    right_dict = where_clause_dict.get('right', {})

                    left_expr = IdentifierExpr(left_dict.get('name', '')) if left_dict.get(
                        'type') == 'IdentifierExpr' else None
                    right_expr = LiteralExpr(right_dict.get('value')) if right_dict.get(
                        'type') == 'LiteralExpr' else None

                    if left_expr and right_expr:
                        where_clause = BinaryExpr(
                            left_expr,
                            where_clause_dict.get('operator', '='),
                            right_expr
                        )

            # åˆ›å»ºSELECTè¯­å¥
            select_stmt = SelectStmt(columns, from_clause)
            select_stmt.where_clause = where_clause

            # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’å¹¶æ‰§è¡Œå­æŸ¥è¯¢
            plan_generator = PlanGenerator(enable_optimization=False, silent_mode=True)
            subquery_plan = plan_generator.generate(select_stmt)


            # æ‰§è¡Œå­æŸ¥è¯¢
            subquery_results = list(self.execute_plan(subquery_plan))

            # æå–å­æŸ¥è¯¢ç»“æœçš„ç¬¬ä¸€åˆ—å€¼
            result_values = []
            for result_row in subquery_results:
                # è·å–ç¬¬ä¸€åˆ—çš„å€¼ï¼ˆå‡è®¾å­æŸ¥è¯¢åªè¿”å›ä¸€åˆ—ï¼‰
                if result_row:
                    first_key = list(result_row.keys())[0]
                    result_values.append(result_row[first_key])

            return result_values

        except Exception as e:
            print(f"DEBUG: Error evaluating subquery: {e}")
            return []

    def execute_filtered_seq_scan(self, table_name: str, condition: Any) -> List[Dict]:
        """æ‰§è¡Œå¸¦è¿‡æ»¤æ¡ä»¶çš„é¡ºåºæ‰«æï¼ˆè°“è¯ä¸‹æ¨ä¼˜åŒ–ï¼‰"""
        try:
            # è·å–æ‰€æœ‰è¡Œæ•°æ®
            all_rows = self.storage_engine.get_all_rows(table_name)

            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            filtered_rows = []
            for row in all_rows:
                if self.evaluate_condition(row, condition):
                    filtered_rows.append(row)

            return filtered_rows
        except Exception as e:
            raise SemanticError(f"æ‰«æè¡¨ {table_name} é”™è¯¯: {str(e)}")

    def execute_join(self, join_type: str, on_condition: Any, children: List[Operator]) -> List[Dict]:
        """æ‰§è¡ŒJOINæ“ä½œ"""
        try:
            # å…ˆæ‰§è¡Œå·¦å³å­è®¡åˆ’
            left_results = list(self.execute_plan(children[0]))
            right_results = list(self.execute_plan(children[1]))

            print(f"DEBUG: JOIN - Left results columns: {list(left_results[0].keys()) if left_results else 'None'}")
            print(f"DEBUG: JOIN - Right results columns: {list(right_results[0].keys()) if right_results else 'None'}")

            # è·å–å·¦å³è¡¨çš„çœŸå®åˆ«åï¼ˆä»æ“ä½œç¬¦ä¸­è·å–ï¼‰
            left_alias = getattr(children[0], 'table_alias', None) or "left_table"
            right_alias = getattr(children[1], 'table_alias', None) or "right_table"

            print(f"DEBUG: JOIN - Left alias: {left_alias}, Right alias: {right_alias}")

            joined_results = []

            # å¤„ç†ä¸åŒçš„JOINç±»å‹
            if join_type.upper() == 'INNER':
                for left_row in left_results:
                    for right_row in right_results:
                        # åˆ›å»ºåˆå¹¶çš„è¡Œï¼Œä½¿ç”¨å®Œæ•´çš„é™å®šåˆ—å
                        merged_row = {}

                        # æ·»åŠ å·¦è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in left_row.items():
                            merged_row[f"{left_alias}.{key}"] = value

                        # æ·»åŠ å³è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in right_row.items():
                            merged_row[f"{right_alias}.{key}"] = value

                        # è¯„ä¼°ONæ¡ä»¶
                        if self.evaluate_condition(merged_row, on_condition):
                            joined_results.append(merged_row)

            elif join_type.upper() == 'LEFT':
                for left_row in left_results:
                    matched = False
                    for right_row in right_results:
                        # åˆ›å»ºåˆå¹¶çš„è¡Œï¼Œä½¿ç”¨å®Œæ•´çš„é™å®šåˆ—å
                        merged_row = {}

                        # æ·»åŠ å·¦è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in left_row.items():
                            merged_row[f"{left_alias}.{key}"] = value

                        # æ·»åŠ å³è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in right_row.items():
                            merged_row[f"{right_alias}.{key}"] = value

                        if self.evaluate_condition(merged_row, on_condition):
                            joined_results.append(merged_row)
                            matched = True

                    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œæ·»åŠ å·¦è¡¨è¡Œï¼Œå³è¡¨åˆ—ä¸ºNULL
                    if not matched:
                        null_row = {}
                        # æ·»åŠ å·¦è¡¨åˆ—
                        for key, value in left_row.items():
                            null_row[f"{left_alias}.{key}"] = value
                        # æ·»åŠ å³è¡¨NULLå€¼
                        for key in right_results[0].keys():
                            null_row[f"{right_alias}.{key}"] = None
                        joined_results.append(null_row)

            elif join_type.upper() == 'RIGHT':
                for right_row in right_results:
                    matched = False
                    for left_row in left_results:
                        # åˆ›å»ºåˆå¹¶çš„è¡Œï¼Œä½¿ç”¨å®Œæ•´çš„é™å®šåˆ—å
                        merged_row = {}

                        # æ·»åŠ å·¦è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in left_row.items():
                            merged_row[f"{left_alias}.{key}"] = value

                        # æ·»åŠ å³è¡¨åˆ—ï¼ŒåŠ ä¸Šè¡¨åˆ«åå‰ç¼€
                        for key, value in right_row.items():
                            merged_row[f"{right_alias}.{key}"] = value

                        if self.evaluate_condition(merged_row, on_condition):
                            joined_results.append(merged_row)
                            matched = True

                    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œæ·»åŠ å³è¡¨è¡Œï¼Œå·¦è¡¨åˆ—ä¸ºNULL
                    if not matched:
                        null_row = {}
                        # æ·»åŠ å·¦è¡¨NULLå€¼
                        for key in left_results[0].keys():
                            null_row[f"{left_alias}.{key}"] = None
                        # æ·»åŠ å³è¡¨åˆ—
                        for key, value in right_row.items():
                            null_row[f"{right_alias}.{key}"] = value
                        joined_results.append(null_row)

            else:
                raise SemanticError(f"ä¸æ”¯æŒçš„JOINç±»å‹: {join_type}")

            print(f"DEBUG: JOIN - Result: {len(joined_results)} rows")
            if joined_results:
                print(f"DEBUG: JOIN - First result row keys: {list(joined_results[0].keys())}")
            return joined_results

        except Exception as e:
            raise SemanticError(f"JOINæ“ä½œé”™è¯¯: {str(e)}")

    def execute_index_scan(self, table_name: str, index_name: str, scan_condition: Any) -> List[Dict]:
        """æ‰§è¡Œç´¢å¼•æ‰«æ"""
        try:
            # ä»æ¡ä»¶ä¸­æå–é”®å€¼ï¼ˆç®€åŒ–å¤„ç†ï¼Œä»…æ”¯æŒç­‰å€¼æŸ¥è¯¢ï¼‰
            key = self._extract_key_from_condition(scan_condition)
            if key is None:
                raise SemanticError("Unsupported index condition")

            # è°ƒç”¨å­˜å‚¨å¼•æ“çš„ç´¢å¼•æŸ¥è¯¢æ–¹æ³•
            rows = self.storage_engine.get_rows_by_index(table_name, index_name, key)
            return rows
        except Exception as e:
            raise SemanticError(f"Index scan error: {str(e)}")

    def _extract_key_from_condition(self, condition: Any) -> Any:
        """ä»æ¡ä»¶ä¸­æå–ç­‰å€¼æŸ¥è¯¢çš„é”®å€¼"""
        if hasattr(condition, 'to_dict'):
            cond_dict = condition.to_dict()
        else:
            cond_dict = condition

        if cond_dict.get('type') == 'BinaryExpr' and cond_dict.get('operator') == '=':
            left = cond_dict.get('left', {})
            right = cond_dict.get('right', {})
            if left.get('type') == 'IdentifierExpr' and right.get('type') == 'LiteralExpr':
                return right.get('value')
        return None

    def execute_create_index(self, index_name: str, table_name: str, columns: List[str], unique: bool,
                             index_type: str) -> str:
        """æ‰§è¡Œåˆ›å»ºç´¢å¼•æ“ä½œ"""
        try:
            # é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not self.catalog.table_exists(table_name):
                raise SemanticError(f"Table '{table_name}' does not exist")

            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ - é€šè¿‡è·å–è¡¨ä¿¡æ¯æ¥éªŒè¯åˆ—
            table_info = self.catalog.get_table(table_name)
            if table_info is None:
                raise SemanticError(f"Table '{table_name}' does not exist")

            # è·å–è¡¨çš„åˆ—ååˆ—è¡¨
            table_columns = [col['name'] for col in table_info['columns']]
            for column in columns:
                if column not in table_columns:
                    raise SemanticError(f"Column '{column}' does not exist in table '{table_name}'")

            # è°ƒç”¨å­˜å‚¨å¼•æ“åˆ›å»ºç´¢å¼•
            success = self.storage_engine.create_index(table_name, index_name, columns[0])  # ä»…æ”¯æŒå•åˆ—ç´¢å¼•
            if not success:
                raise SemanticError("Failed to create index")

            # æ›´æ–°ç³»ç»Ÿç›®å½•
            self.catalog.create_index(index_name, table_name, columns, unique, index_type)

            return f"Index '{index_name}' created successfully"
        except Exception as e:
            raise SemanticError(f"Create index error: {str(e)}")

    def _extract_index_range(self, condition: Any, index_columns: List[str]) -> Tuple[Any, Any]:
        """ä»æ¡ä»¶ä¸­æå–ç´¢å¼•é”®èŒƒå›´"""
        # ç®€åŒ–å®ç°ï¼šå‡è®¾æ˜¯ç­‰å€¼æŸ¥è¯¢æˆ–èŒƒå›´æŸ¥è¯¢
        # å®é™…åº”æ ¹æ®æ¡ä»¶è¡¨è¾¾å¼è§£æå‡ºèŒƒå›´
        if hasattr(condition, 'to_dict'):
            condition_dict = condition.to_dict()
            if condition_dict.get('type') == 'BinaryExpr':
                left = condition_dict.get('left', {})
                right = condition_dict.get('right', {})
                operator = condition_dict.get('operator', '')

                if (left.get('type') == 'IdentifierExpr' and
                        left.get('name') in index_columns and
                        right.get('type') == 'LiteralExpr'):

                    value = right.get('value')
                    if operator == '=':
                        return value, value
                    elif operator == '>':
                        return value, None
                    elif operator == '>=':
                        return value, None
                    elif operator == '<':
                        return None, value
                    elif operator == '<=':
                        return None, value
                    elif operator == 'BETWEEN':
                        # å¤„ç†BETWEENæ“ä½œç¬¦
                        if (isinstance(value, list) and len(value) == 2):
                            return value[0], value[1]

        # é»˜è®¤è¿”å›å…¨èŒƒå›´
        return None, None

    def execute_drop_index(self, index_name: str) -> str:
        """æ‰§è¡Œåˆ é™¤ç´¢å¼•æ“ä½œ"""
        try:
            # ä» catalog è·å–æ‰€æœ‰ç´¢å¼•ä¿¡æ¯
            all_indexes = self.catalog.get_all_indexes()

            if index_name not in all_indexes:
                return f"Index '{index_name}' does not exist"

            # è·å–ç´¢å¼•ä¿¡æ¯
            index_info = all_indexes[index_name]
            table_name = index_info["table"]

            # è°ƒç”¨å­˜å‚¨å¼•æ“åˆ é™¤ç´¢å¼•
            success = self.storage_engine.drop_index(table_name, index_name)
            if not success:
                raise SemanticError(f"Failed to drop index '{index_name}'")

            # æ›´æ–° catalog
            self.catalog.drop_index(index_name)

            return f"Index '{index_name}' dropped successfully"
        except Exception as e:
            raise SemanticError(f"Drop index error: {str(e)}")

    # åœ¨è®¡åˆ’ç”Ÿæˆå™¨ä¸­æ·»åŠ è§†å›¾è¯†åˆ«é€»è¾‘
    def _visit_table_ref(self, node: TableRef):
        table_name = node.table_name

        # æ£€æŸ¥æ˜¯å¦æ˜¯è§†å›¾
        if table_name in self.execution_engine.views:
            view_info = self.execution_engine.views[table_name]
            if 'plan' in view_info:
                # è¿”å›è§†å›¾æ‰«ææ“ä½œç¬¦
                return ViewScanOp(table_name, view_info['plan'])

        # æ™®é€šè¡¨ï¼Œè¿”å›é¡ºåºæ‰«æ
        return SeqScanOp(table_name)

    def execute_show_indexes(self, table_name: Optional[str] = None) -> List[Dict]:
        """æ‰§è¡ŒSHOW INDEXESè¯­å¥"""
        try:
            # ä»catalogè·å–ç´¢å¼•ä¿¡æ¯
            if table_name:
                # è·å–æŒ‡å®šè¡¨çš„ç´¢å¼•
                indexes = self.catalog.get_table_indexes(table_name)  # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
                return [{
                    "Table": table_name,
                    "Index_name": idx["name"],  # ä½¿ç”¨æ­£ç¡®çš„é”®å
                    "Columns": ', '.join(idx["columns"]),
                    "Unique": idx["unique"],  # ä½¿ç”¨æ­£ç¡®çš„é”®å
                    "Index_type": idx["type"]  # ä½¿ç”¨æ­£ç¡®çš„é”®å
                } for idx in indexes]
            else:
                # è·å–æ‰€æœ‰ç´¢å¼•
                all_indexes = self.catalog.get_all_indexes()  # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
                result = []
                for idx_name, idx_info in all_indexes.items():
                    result.append({
                        "Table": idx_info["table"],
                        "Index_name": idx_name,  # ç›´æ¥ä½¿ç”¨ç´¢å¼•å
                        "Columns": ', '.join(idx_info["columns"]),
                        "Unique": idx_info["unique"],
                        "Index_type": idx_info["type"]
                    })
                return result
        except Exception as e:
            raise SemanticError(f"æ˜¾ç¤ºç´¢å¼•é”™è¯¯: {str(e)}")